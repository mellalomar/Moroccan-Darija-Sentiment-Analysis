{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "SENTIMENT_DARIJA .ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ko-nan/nlp/blob/main/SENTIMENT_DARIJA_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHWpAqsBFpNZ",
        "outputId": "f2143241-0135-4876-8e42-3b250d570fcd",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e558a916-9cd6-4096-b256-dc6fd5063f48\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e558a916-9cd6-4096-b256-dc6fd5063f48\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving list.txt to list.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TizlRC7ZGLY0",
        "outputId": "5032b679-10b4-46c6-f942-36c0cd2dc779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "!pip install PyArabic"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyArabic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/e2/46728ec2f6fe14970de5c782346609f0636262c0941228f363710903aaa1/PyArabic-0.6.10.tar.gz (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 1.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyArabic\n",
            "  Building wheel for PyArabic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyArabic: filename=PyArabic-0.6.10-cp36-none-any.whl size=113325 sha256=e61f1659dff9d2f77bb6e2386efed388a430ecd7e81141e174723919d95a0a5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/b8/f5/b7c1a50e6efb83544844f165a9b134afe7292585465e29b61d\n",
            "Successfully built PyArabic\n",
            "Installing collected packages: PyArabic\n",
            "Successfully installed PyArabic-0.6.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP-JFV69HZqD",
        "outputId": "05710477-a351-4149-ebd8-2f17c0e77016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "!pip install Tashaphyne"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Tashaphyne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/80/8b94a7d91c92d252cc395d80ebf9e4b2fa5bdd0c3fbf10b4a1749817c998/Tashaphyne-0.3.4.1-py3-none-any.whl (244kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 17.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 844kB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 1.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40kB 1.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 51kB 982kB/s eta 0:00:01\r\u001b[K     |████████                        | 61kB 1.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 71kB 1.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 81kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 92kB 1.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 102kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 112kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 122kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 133kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 143kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 153kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 163kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 174kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 184kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 194kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 204kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 215kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 225kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 235kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarabic in /usr/local/lib/python3.6/dist-packages (from Tashaphyne) (0.6.10)\n",
            "Installing collected packages: Tashaphyne\n",
            "Successfully installed Tashaphyne-0.3.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHlsS9CaFm_5"
      },
      "source": [
        "import pyarabic.araby as araby\n",
        "import re\n",
        "import string\n",
        "import unicodedata as ud\n",
        "import codecs\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from tashaphyne.stemming import ArabicLightStemmer\n",
        "from itertools import islice\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV \n",
        "from scipy import stats\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FmdoVpFFm_-"
      },
      "source": [
        "######### GET DATA ##############\n",
        "\n",
        "#import  stop words \n",
        "def get_stop_words():\n",
        "    path = \"stop_words.txt\"\n",
        "    stop_words = []\n",
        "    with codecs.open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
        "        stop_words = myfile.readlines()\n",
        "    stop_words = [word.strip() for word in stop_words]\n",
        "    return stop_words\n",
        "\n",
        "# import Emojis \n",
        "def get_emojis():\n",
        "    with codecs.open(\"emoji.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
        "         positive_emoji=myfile.read()\n",
        "    positive_emoji=positive_emoji.split(\"\\r\\n\")\n",
        "    positive_emoji=positive_emoji[1:len(positive_emoji)-1] \n",
        "    with codecs.open(\"neg_emoji.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfie:\n",
        "        neg_emoji=myfie.read()\n",
        "    neg_emoji=neg_emoji.split(\"\\r\\n\")\n",
        "    neg_emoji=neg_emoji[1:len(neg_emoji)-1]\n",
        "    return positive_emoji,neg_emoji\n",
        "    \n",
        "\n",
        "#import (Text , label) \n",
        "def get_data():\n",
        "    path=\"data_text.txt\"\n",
        "    with codecs.open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
        "        text = myfile.read()\n",
        "    sentences=text.split(\"@\")\n",
        "    sentences=[x.split(\"\\r\\n\") for x in sentences]\n",
        "    sentences=sentences[1:len(sentences)-1]\n",
        "    df=pd.DataFrame(sentences)\n",
        "    df.columns = ['sentiment','sentence']\n",
        "    return df\n",
        "\n",
        "############## PREPROCESSING DATA ################\n",
        "\n",
        "\n",
        "#Remove stop words \n",
        "def remove_stp_words(text):\n",
        "    text_words = []\n",
        "    words = text.split(\" \")\n",
        "    stop_words = get_stop_words()\n",
        "    for word in words:\n",
        "        if word not in stop_words:\n",
        "            text_words.append(word)\n",
        "    return ' '.join(text_words)\n",
        "\n",
        "\n",
        "#Emoticons_Regex \n",
        "emoticons_str = r\"\"\"\n",
        "    (?:\n",
        "        [:=;] # Eyes\n",
        "        [oO\\-]? # Nose (optional)\n",
        "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
        "    )\"\"\"\n",
        "regex_str = [\n",
        "    emoticons_str,\n",
        "    r'<[^>]+>',  # HTML tags\n",
        "    r'(?:@[\\w_]+)',  # @-mentions\n",
        "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\",  # hash-tags\n",
        "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+',  # URLs\n",
        "\n",
        "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)',  # numbers\n",
        "    r\"(?:[a-z][a-z'\\-_]+[a-z])\",  # words with - and '\n",
        "    r'(?:[\\w_]+)',  # other words\n",
        "    r'(?:\\S)'  # anything else\n",
        "]\n",
        "tokens_re = re.compile(r'(' + '|'.join(regex_str) + ')', re.VERBOSE | re.IGNORECASE)\n",
        "emoticon_re = re.compile(r'^' + emoticons_str + '$', re.VERBOSE | re.IGNORECASE)\n",
        "\n",
        "#Tokenizing_the_text :\n",
        "def tokenize(s):\n",
        "    return tokens_re.findall(s)\n",
        "\n",
        "\n",
        "#Normalize_the_text:\n",
        "def normalize_arabic(text):\n",
        "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
        "    text = re.sub(\"ى\", \"ي\", text)\n",
        "    text = re.sub(\"ؤ\", \"ء\", text)\n",
        "    text = re.sub(\"ئ\", \"ء\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    text = re.sub(\"گ\", \"ك\", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "#Remove-repeating_char :\n",
        "def remove_repeating_char(text):\n",
        "     #return re.sub(r'(.)\\1+', r'\\1', text)     # keep only 1 repeat\n",
        "    return re.sub(r'(.)\\1+', r'\\1\\1', text)     # keep 2 repeat\n",
        "\n",
        "#Detecting_Emojis_REGEX\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "         u\"\\U00002702-\\U000027B0\"\n",
        "         u\"\\U000024C2-\\U0001F251\"\n",
        "         \"]+\", flags=re.UNICODE)\n",
        "\n",
        "#Transform Emojis to their sentiment \n",
        "def emoji_to_text(text):\n",
        "    text_words = []\n",
        "    words = text.split(\" \")\n",
        "    positive_emoji,neg_emoji=get_emojis()\n",
        "    for word in words:\n",
        "        if emoji_pattern.search(word):\n",
        "            if word in positive_emoji :\n",
        "                word='ايجابي'\n",
        "            if word in neg_emoji :\n",
        "                word='سلبي'\n",
        "        text_words.append(word)\n",
        "    return ' '.join(text_words)\n",
        "\n",
        "#REMOVING_Punctuation\n",
        "def remove_punc(text):\n",
        "    return ''.join(c for c in text if not ud.category(c).startswith('P'))\n",
        "\n",
        "\n",
        "#Stemmer_LIGHT : Remove suffixes and affixes \n",
        "ArListem = ArabicLightStemmer()\n",
        "def stemmer_light(text):\n",
        "    text_words = []\n",
        "    words = text.split(\" \")\n",
        "    for c in words:\n",
        "        stem = ArListem.light_stem(c)\n",
        "        text_words.append(stem)\n",
        "    return ' '.join(text_words)\n",
        "\n",
        "#Root Stemming :  Transform the wrod into its root form\n",
        "def stemmer_root(text):\n",
        "    text_words = []\n",
        "    words = text.split(\" \")\n",
        "    for c in words:\n",
        "        stem = ArListem.light_stem(c)\n",
        "        text_words.append(stem)\n",
        "    return ' '.join(text_words)\n",
        "\n",
        "\n",
        "############ DARIJA TEXT PREPROCESSIG #########\n",
        "\n",
        "def data_clean(stp_words=False,stem=True,tok=True,emojis=False):\n",
        "    data = get_data()\n",
        "    sentences = data['sentence']\n",
        "    #Remove ـــ character wich is used a lot in arabic for exhibition\n",
        "    sentences = [araby.strip_tatweel(text) for text in sentences] \n",
        "    #Remove Punctiation \n",
        "    sentences = [remove_punc(text) for text in sentences]\n",
        "    if emojis==False :\n",
        "        sentences = [emoji_to_text(text) for text in sentences] \n",
        "    #Remove Repeating character\n",
        "    sentences = [remove_repeating_char(text) for text in sentences]\n",
        "    #Remoce arabic diacritics\n",
        "    sentences = [araby.strip_tashkeel(text) for text in sentences]\n",
        "    if stp_words==True :\n",
        "        sentences = [remove_stp_words(text) for text in sentences]\n",
        "    if stem==True:\n",
        "        sentences = [stemmer_light(text) for text in sentences]\n",
        "    sentences = [normalize_arabic(text) for text in sentences]\n",
        "    sentences = [araby.normalize_hamza(text) for text in sentences]\n",
        "    if tok==True:\n",
        "        sentences = [tokenize(text) for text in sentences]\n",
        "    return sentences         "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT0NMY-cFnAB",
        "outputId": "46277ac6-e811-4f1c-ed80-7f24dcf5e4c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "######## TF_IDF ############ TERM FREQUENCY _ INVERSE DOCUMENT FREQUENCY\n",
        "def get_tfidf():\n",
        "    data,sentiment = data_clean(stp_words=True,stem=True,tok=False,emojis=False)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data, sentiment, test_size=0.2, random_state=1)\n",
        "    vectorizer = TfidfVectorizer(ngram_range = (1,1))\n",
        "    X_tr = vectorizer.fit_transform(X_train)\n",
        "    X_tes = vectorizer.transform(X_test)\n",
        "    return X_tr,X_tes,y_train,y_test\n",
        "########## Document-Term Matrix(DTM) ######\n",
        "def doc_term_frec():\n",
        "    data,sentiment = data_clean(stp_words=True,stem=True,tok=False,emojis=False)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data, sentiment, test_size=0.2, random_state=1)\n",
        "    cv = CountVectorizer(ngram_range = (1,1))\n",
        "    X_tr= cv.fit_transform(X_train)\n",
        "    X_tes = cv.transform(X_test)\n",
        "    return X_tr,X_tes,y_train,y_test\n",
        "\n",
        "\n",
        "\n",
        "plt.bar([\"Positive\",\"Negative\"],[sentiment[sentiment=='P'].count(),sentiment[sentiment=='N'].count()],color=['g','b']) "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 2 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-DvEUqjFnAG",
        "outputId": "11b0b5c2-c33e-4493-e651-2382d7776590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "data_set =get_data()\n",
        "sentiment = data_set['sentiment']\n",
        "sentimen =np.array( [1 if sen == 'P' else 0 for sen in sentiment])\n",
        "\n",
        "X_train, X_test, y_train, y_test = doc_term_frec()\n",
        "print(X_train.shape,y_train.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-2336d5dfde70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msentimen\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msen\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'P'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_term_frec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-14c4a5bba5fa>\u001b[0m in \u001b[0;36mdoc_term_frec\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m########## Document-Term Matrix(DTM) ######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdoc_term_frec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memojis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21V_9E1GFnAI",
        "outputId": "ac32503e-2130-4319-e52f-401f7614f424"
      },
      "source": [
        "clf = MultinomialNB(alpha=0.1, fit_prior= False).fit(X_train, y_train)\n",
        "log = LogisticRegression( solver='lbfgs',multi_class='multinomial').fit(X_train, y_train)                                                                    \n",
        "d_tree = tree.DecisionTreeClassifier().fit(X_train,y_train)\n",
        "svm = LinearSVC().fit(X_train,y_train)\n",
        "print(classification_report( log.predict(X_test) , y_test))\n",
        "print(\"Logistic Regression:\",accuracy_score( log.predict(X_test) , y_test ),accuracy_score( log.predict(X_train) , y_train ))\n",
        "print(classification_report( d_tree.predict(X_test) , y_test))\n",
        "print(\"Decision Tree Accuracy:\",accuracy_score( d_tree.predict(X_test) , y_test ),accuracy_score( d_tree.predict(X_train) , y_train ))\n",
        "print(classification_report( clf.predict(X_test) , y_test))\n",
        "print(\"MultinomialNB Accuracy:\",accuracy_score( clf.predict(X_test) , y_test ),accuracy_score( clf.predict(X_train) , y_train ))\n",
        "print(classification_report( svm.predict(X_test) , y_test))\n",
        "print(\"SVM Accuracy:\",accuracy_score( svm.predict(X_test) , y_test ),accuracy_score( svm.predict(X_train) , y_train ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.87      0.82       192\n",
            "           1       0.87      0.77      0.82       219\n",
            "\n",
            "    accuracy                           0.82       411\n",
            "   macro avg       0.82      0.82      0.82       411\n",
            "weighted avg       0.82      0.82      0.82       411\n",
            "\n",
            "Logistic Regression: 0.8175182481751825 0.9987819732034104\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.74      0.79       248\n",
            "           1       0.66      0.79      0.72       163\n",
            "\n",
            "    accuracy                           0.76       411\n",
            "   macro avg       0.75      0.76      0.75       411\n",
            "weighted avg       0.77      0.76      0.76       411\n",
            "\n",
            "Decision Tree Accuracy: 0.7591240875912408 0.9993909866017052\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.87      0.79       182\n",
            "           1       0.88      0.74      0.80       229\n",
            "\n",
            "    accuracy                           0.80       411\n",
            "   macro avg       0.80      0.81      0.80       411\n",
            "weighted avg       0.81      0.80      0.80       411\n",
            "\n",
            "MultinomialNB Accuracy: 0.7980535279805353 0.9957369062119367\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.87      0.79       181\n",
            "           1       0.88      0.74      0.80       230\n",
            "\n",
            "    accuracy                           0.80       411\n",
            "   macro avg       0.80      0.80      0.80       411\n",
            "weighted avg       0.81      0.80      0.80       411\n",
            "\n",
            "SVM Accuracy: 0.7956204379562044 0.9987819732034104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVpFE6CDFnAL",
        "outputId": "bfed494f-9f41-4068-be7e-ca5478150023"
      },
      "source": [
        "####### Tuning Hyperparameters ####### \n",
        "\n",
        "#Grid Search For SVM\n",
        "def svc_param_selection(X, y, nfolds):\n",
        "    Cs = [9.5,9]\n",
        "    gammas = [0.25,0.2]\n",
        "    param_grid = {'C': Cs, 'gamma' : gammas,'kernel' : ['rbf']}\n",
        "    grid_search = GridSearchCV(SVC(), param_grid, cv=nfolds)\n",
        "    grid_search.fit(X, y)\n",
        "    grid_search.best_params_\n",
        "    return grid_search.best_score_,grid_search.best_params_\n",
        "\n",
        "svc_param_selection(X_train, y_train, 5)\n",
        "\n",
        "#Grid Search For Naive Bayes \n",
        "def svc_param_selection(X, y):\n",
        "    grid_params = {\n",
        "      'alpha': [0.35,0.3,0.25],\n",
        "      'fit_prior': [True, False]}\n",
        "    crossvalidation=KFold(n_splits=100,shuffle=True,random_state=1)\n",
        "    cl = GridSearchCV(clf, grid_params,cv=crossvalidation)\n",
        "    cl.fit(X, y)\n",
        "    return cl.best_params_,cl.best_score_\n",
        "##### Random Search for SVM\n",
        "\n",
        "\n",
        "rand_list = {\"C\": stats.uniform(2, 10),\n",
        "             \"gamma\": stats.uniform(0.01, 1),\n",
        "            \"kernel\":['rbf','linear','sigmoid']}\n",
        "              \n",
        "rand_search = RandomizedSearchCV(svm, param_distributions = rand_list, n_iter = 20, n_jobs = 4, cv = 3, random_state = 2) \n",
        "rand_search.fit(X_train, y_train) \n",
        "rand_search.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-53ed7ab3432b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0msvc_param_selection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msvc_param_selection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    }
  ]
}